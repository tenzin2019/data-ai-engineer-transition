# LangChain Configuration for RAG Conversational AI Assistant
langchain:
  models:
    openai:
      gpt-4:
        model_name: "gpt-4o"
        temperature: 0.7
        max_tokens: 2000
        streaming: true
        timeout: 60
        
      gpt-3.5-turbo:
        model_name: "gpt-3.5-turbo"
        temperature: 0.7
        max_tokens: 1500
        streaming: true
        timeout: 30
        
    azure_openai:
      gpt-4:
        deployment_name: "gpt-4o"
        model_name: "gpt-4o"
        temperature: 0.7
        max_tokens: 2000
        streaming: true
        timeout: 60
        
      gpt-35-turbo:
        deployment_name: "gpt-35-turbo"
        model_name: "gpt-35-turbo"
        temperature: 0.7
        max_tokens: 1500
        streaming: true
        timeout: 30
        
    anthropic:
      claude-3-sonnet:
        model: "claude-3-sonnet-20240229"
        temperature: 0.7
        max_tokens: 2000
        timeout: 60
        
      claude-3-haiku:
        model: "claude-3-haiku-20240307"
        temperature: 0.7
        max_tokens: 1500
        timeout: 30
  
  embeddings:
    openai:
      ada-002:
        model: "text-embedding-ada-002"
        chunk_size: 1000
        
    azure_openai:
      ada-002:
        deployment: "text-embedding-ada-002"
        model: "text-embedding-ada-002"
        chunk_size: 1000
        
    huggingface:
      all-minilm-l6-v2:
        model_name: "sentence-transformers/all-MiniLM-L6-v2"
        device: "cpu"
        
      all-mpnet-base-v2:
        model_name: "sentence-transformers/all-mpnet-base-v2"
        device: "cpu"
  
  vector_stores:
    chroma:
      persist_directory: "./chroma_db"
      collection_name: "rag_documents"
      
    pinecone:
      index_name: "rag-assistant"
      dimension: 1536
      metric: "cosine"
      
    weaviate:
      url: "http://localhost:8080"
      index_name: "Documents"
      
    faiss:
      index_type: "IndexFlatIP"
      dimension: 1536
  
  chains:
    retrieval_qa:
      chain_type: "stuff"
      search_kwargs:
        k: 4
      return_source_documents: true
      
    conversational_retrieval:
      search_kwargs:
        k: 4
      return_source_documents: true
      max_tokens_limit: 3000
      
    map_reduce:
      chunk_size: 4000
      chunk_overlap: 200
      
  memory:
    conversation_buffer:
      memory_key: "chat_history"
      return_messages: true
      output_key: "answer"
      
    conversation_summary:
      memory_key: "chat_history"
      return_messages: true
      output_key: "answer"
      max_token_limit: 2000
  
  text_splitters:
    recursive_character:
      chunk_size: 1000
      chunk_overlap: 200
      separators: ["\n\n", "\n", " ", ""]
      
    token:
      chunk_size: 1000
      chunk_overlap: 200
      
  prompts:
    qa_template: |
      Use the following pieces of context to answer the question at the end. 
      If you don't know the answer, just say that you don't know, don't try to make up an answer.
      
      Context:
      {context}
      
      Question: {question}
      Answer:
      
    conversational_template: |
      Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.
      
      Chat History:
      {chat_history}
      Follow Up Input: {question}
      Standalone question:
      
    summarization_template: |
      Please provide a concise summary of the following text:
      
      Text: {text}
      
      Summary:
  
  tools:
    web_search:
      enabled: false
      api_key: null
      
    calculator:
      enabled: true
      
    python_repl:
      enabled: false
      
    document_search:
      enabled: true
      
  agents:
    conversational_react:
      agent_type: "conversational-react-description"
      verbose: true
      max_iterations: 3
      
    zero_shot_react:
      agent_type: "zero-shot-react-description"
      verbose: true
      max_iterations: 3
      
  monitoring:
    langsmith:
      enabled: false
      project_name: "rag-conversational-ai"
      
    wandb:
      enabled: false
      project_name: "rag-conversational-ai"
      
  caching:
    enabled: true
    backend: "sqlite"
    database_path: "./langchain_cache.db"